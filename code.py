import streamlit as st
import pandas as pd
import numpy as np
from datetime import datetime
import plotly.graph_objects as go
import plotly.express as px
from io import BytesIO
import warnings
warnings.filterwarnings('ignore')

st.set_page_config(page_title="Anomali Tespiti Sistemi", layout="wide")

st.title("ğŸ” Anomali Tespiti Sistemi - DetaylÄ± Analiz")
st.markdown("---")

# Sidebar - Ayarlar
with st.sidebar:
    st.header("âš™ï¸ YapÄ±landÄ±rma")
    
    st.subheader("ğŸ“Š Anomali AlgÄ±lama YÃ¶ntemi")
    detection_method = st.radio(
        "Hangi yÃ¶ntemi kullanmak istiyorsun?",
        ["Standart Sapma (Z-Score)", "IQR (Ã‡eyrekler ArasÄ±)", "KarÅŸÄ±laÅŸtÄ±rmalÄ± Analiz"]
    )
    
    if detection_method == "Standart Sapma (Z-Score)":
        threshold = st.slider("Z-Score EÅŸik DeÄŸeri", 1.0, 3.0, 2.0, 0.1)
        st.caption("2.0 = Normal sapmalarÄ±, 3.0 = Extreme sapmalarÄ± yakalar")
    
    elif detection_method == "IQR (Ã‡eyrekler ArasÄ±)":
        multiplier = st.slider("IQR Ã‡arpanÄ±", 1.0, 3.0, 1.5, 0.1)
        st.caption("1.5 = Standart, 3.0 = Ã‡ok katÄ±")
    
    else:
        comp_threshold = st.slider("KarÅŸÄ±laÅŸtÄ±rma EÅŸik (%)", 10, 50, 25)
        st.caption("Referans deÄŸerden % sapma")

# Veri YÃ¼kleme
st.header("ğŸ“ AdÄ±m 1: Veri YÃ¼kleme")

uploaded_file = st.file_uploader("Excel dosyasÄ±nÄ± yÃ¼kle", type=["xlsx", "xls"])

if uploaded_file:
    df = pd.read_excel(uploaded_file)
    
    col1, col2 = st.columns(2)
    with col1:
        st.metric("Tespit Edilen Tesisat SayÄ±sÄ±", len(df))
    with col2:
        st.metric("Tespit Edilen DÃ¶nem SayÄ±sÄ±", len(df.columns) - 1)
    
    st.subheader("ğŸ“‹ YÃ¼klenen Veri Ã–rneÄŸi")
    st.dataframe(df.head(10), use_container_width=True)
    
    # ============ VERÄ° DÃ–NÃœÅTÃœRME ============
    st.header("ğŸ”„ AdÄ±m 2: Veri HazÄ±rlama ve NormalleÅŸtirilme")
    
    facility_col = df.columns[0]
    date_columns = df.columns[1:]
    
    # Tarihleri parse et
    dates_parsed = []
    days_in_period = []
    
    for date_str in date_columns:
        try:
            date_obj = pd.to_datetime(date_str)
            dates_parsed.append(date_obj)
            day_num = int(str(date_str).split('.')[0])
            days_in_period.append(day_num)
        except:
            pass
    
    # Veriyi dÃ¶nÃ¼ÅŸtÃ¼r
    data_list = []
    
    for facility in df[facility_col]:
        for i, date in enumerate(dates_parsed):
            consumption_value = df[df[facility_col] == facility].iloc[0, i+1]
            
            if isinstance(consumption_value, str) and '#YOK' in str(consumption_value):
                continue
            
            try:
                consumption_value = float(consumption_value)
            except:
                continue
            
            day_count = days_in_period[i]
            normalized = (consumption_value / day_count) * 30
            
            data_list.append({
                'facility_id': facility,
                'date': date,
                'year': date.year,
                'month': date.month,
                'month_name': date.strftime('%b %Y'),
                'days_reported': day_count,
                'raw_consumption': consumption_value,
                'normalized_consumption': normalized
            })
    
    df_work = pd.DataFrame(data_list)
    
    # NormalleÅŸtirilme aÃ§Ä±klamasÄ±
    with st.expander("ğŸ“š NormalleÅŸtirilme NasÄ±l Ã‡alÄ±ÅŸÄ±yor?"):
        st.markdown("""
        ### NormalleÅŸtirilme FormÃ¼lÃ¼:
        ```
        NormalleÅŸtirilmiÅŸ TÃ¼ketim = (Ham TÃ¼ketim / Raporlanan GÃ¼n SayÄ±sÄ±) Ã— 30
        ```
        
        **Ã–rnek:**
        - KasÄ±m ayÄ±nda 24 gÃ¼n iÃ§in 22.874 mÂ³ tÃ¼ketim
        - GÃ¼nlÃ¼k ortalama = 22.874 / 24 = 0.953 mÂ³/gÃ¼n
        - 30 gÃ¼nde tahmini = 0.953 Ã— 30 = **28.59 mÂ³**
        
        **Neden yapÄ±yoruz?**
        - Aylar farklÄ± gÃ¼n sayÄ±larÄ±na sahip (28-31 gÃ¼n)
        - KÄ±smi veri (24 gÃ¼n gibi) tam aya Ã§Ä±karmak iÃ§in
        - TÃ¼m dÃ¶nemleri karÅŸÄ±laÅŸtÄ±rÄ±labilir hale getirmek
        """)
    
    st.success("âœ… Veriler normalleÅŸtirildi!")
    
    # ============ ANOMALÄ° TESPÄ°TÄ° ============
    st.header("ğŸ¯ AdÄ±m 3: Anomali Tespit YÃ¶ntemleri")
    
    def apply_zscore_detection(group, threshold):
        """Z-Score tabanlÄ± anomali tespiti"""
        mean = group['normalized_consumption'].mean()
        std = group['normalized_consumption'].std()
        
        if std == 0:
            group['z_score'] = 0
            group['method_anomaly'] = False
        else:
            group['z_score'] = np.abs((group['normalized_consumption'] - mean) / std)
            group['method_anomaly'] = group['z_score'] > threshold
        
        return group
    
    def apply_iqr_detection(group, multiplier):
        """IQR tabanlÄ± anomali tespiti"""
        Q1 = group['normalized_consumption'].quantile(0.25)
        Q3 = group['normalized_consumption'].quantile(0.75)
        IQR = Q3 - Q1
        
        lower_bound = Q1 - (multiplier * IQR)
        upper_bound = Q3 + (multiplier * IQR)
        
        group['iqr_lower'] = lower_bound
        group['iqr_upper'] = upper_bound
        group['method_anomaly'] = (group['normalized_consumption'] < lower_bound) | (group['normalized_consumption'] > upper_bound)
        
        return group
    
    def apply_comparative_detection(group, threshold):
        """KarÅŸÄ±laÅŸtÄ±rmalÄ± anomali tespiti"""
        mean = group['normalized_consumption'].mean()
        
        group['deviation_percent'] = np.abs((group['normalized_consumption'] - mean) / mean * 100)
        group['method_anomaly'] = group['deviation_percent'] > threshold
        
        return group
    
    # SeÃ§ilen yÃ¶ntemi uygula
    if detection_method == "Standart Sapma (Z-Score)":
        df_analysis = df_work.groupby('facility_id', group_keys=False).apply(
            lambda x: apply_zscore_detection(x, threshold)
        )
        method_name = f"Z-Score (EÅŸik: {threshold})"
    
    elif detection_method == "IQR (Ã‡eyrekler ArasÄ±)":
        df_analysis = df_work.groupby('facility_id', group_keys=False).apply(
            lambda x: apply_iqr_detection(x, multiplier)
        )
        method_name = f"IQR (Ã‡arpan: {multiplier})"
    
    else:
        df_analysis = df_work.groupby('facility_id', group_keys=False).apply(
            lambda x: apply_comparative_detection(x, comp_threshold)
        )
        method_name = f"KarÅŸÄ±laÅŸtÄ±rmalÄ± (EÅŸik: {comp_threshold}%)"
    
    df_analysis['is_anomaly'] = df_analysis['method_anomaly']
    
    # ============ SONUÃ‡LAR ============
    st.header("ğŸ“ˆ AdÄ±m 4: SonuÃ§lar")
    
    col1, col2, col3, col4 = st.columns(4)
    with col1:
        st.metric("ğŸ“Š Toplam Veri NoktasÄ±", len(df_analysis))
    with col2:
        st.metric("ğŸ¢ Toplam Tesisat", df_analysis['facility_id'].nunique())
    with col3:
        anomalies_count = df_analysis[df_analysis['is_anomaly']].shape[0]
        st.metric("ğŸš¨ Anomali SayÄ±sÄ±", anomalies_count)
    with col4:
        anomaly_pct = (anomalies_count / len(df_analysis) * 100) if len(df_analysis) > 0 else 0
        st.metric("âš ï¸ Anomali OranÄ±", f"{anomaly_pct:.1f}%")
    
    st.markdown(f"**KullanÄ±lan YÃ¶ntem:** {method_name}")
    
    # ============ ANOMALÄ° DETAYLARI ============
    st.subheader("ğŸš¨ Tespit Edilen Anomaliler")
    
    anomalies_df = df_analysis[df_analysis['is_anomaly']].copy().sort_values('normalized_consumption', ascending=False)
    
    if len(anomalies_df) > 0:
        # Filtreleme
        col1, col2, col3 = st.columns(3)
        with col1:
            selected_facilities = st.multiselect(
                "Tesisat Filtrele",
                sorted(anomalies_df['facility_id'].unique()),
                default=sorted(anomalies_df['facility_id'].unique())[:5]
            )
        
        filtered_anomalies = anomalies_df[anomalies_df['facility_id'].isin(selected_facilities)]
        
        # DetaylÄ± tablo
        display_df = filtered_anomalies[['facility_id', 'month_name', 'raw_consumption', 
                                         'days_reported', 'normalized_consumption']].copy()
        display_df.columns = ['Tesisat ID', 'DÃ¶nem', 'Ham TÃ¼ketim (mÂ³)', 'GÃ¼n', 'Norm. TÃ¼ketim (30g)']
        display_df['Ham TÃ¼ketim (mÂ³)'] = display_df['Ham TÃ¼ketim (mÂ³)'].round(2)
        display_df['Norm. TÃ¼ketim (30g)'] = display_df['Norm. TÃ¼ketim (30g)'].round(2)
        
        st.dataframe(display_df, use_container_width=True)
        
        # Her anomaliyi detaylÄ± gÃ¶ster
        st.subheader("ğŸ“Œ Anomali DetaylarÄ±")
        
        for idx, row in filtered_anomalies.iterrows():
            with st.expander(f"ğŸ” {row['facility_id']} - {row['month_name']}"):
                col1, col2, col3, col4 = st.columns(4)
                with col1:
                    st.write("**Ham TÃ¼ketim**")
                    st.write(f"{row['raw_consumption']:.2f} mÂ³")
                with col2:
                    st.write("**Raporlanan GÃ¼n**")
                    st.write(f"{row['days_reported']} gÃ¼n")
                with col3:
                    st.write("**Norm. TÃ¼ketim**")
                    st.write(f"{row['normalized_consumption']:.2f} mÂ³")
                with col4:
                    st.write("**Durum**")
                    st.error("ğŸš¨ ANOMALI")
                
                if detection_method == "Standart Sapma (Z-Score)":
                    st.write(f"**Z-Score DeÄŸeri:** {row['z_score']:.2f} (EÅŸik: {threshold})")
                elif detection_method == "KarÅŸÄ±laÅŸtÄ±rmalÄ± Analiz":
                    st.write(f"**Sapma YÃ¼zdesi:** {row['deviation_percent']:.1f}% (EÅŸik: {comp_threshold}%)")
    else:
        st.info("âœ… Anomali tespit edilmedi!")
    
    # ============ GÃ–RSELLEÅTIRME ============
    st.header("ğŸ“Š AdÄ±m 5: GÃ¶rselleÅŸtirme")
    
    viz_type = st.tabs(["Tesisat Analizi", "Genel DaÄŸÄ±lÄ±m", "KarÅŸÄ±laÅŸtÄ±rma"])
    
    with viz_type[0]:
        st.subheader("ğŸ“ˆ Tesisat DetaylÄ± Analizi")
        facilities = sorted(df_analysis['facility_id'].unique())
        selected_facility = st.selectbox("Tesisat SeÃ§:", facilities, key="facility_select")
        
        facility_data = df_analysis[df_analysis['facility_id'] == selected_facility].sort_values('date')
        
        if len(facility_data) > 0:
            col1, col2 = st.columns(2)
            
            with col1:
                fig = go.Figure()
                
                normal_data = facility_data[~facility_data['is_anomaly']]
                anomaly_data = facility_data[facility_data['is_anomaly']]
                
                fig.add_trace(go.Scatter(
                    x=normal_data['month_name'],
                    y=normal_data['normalized_consumption'],
                    mode='lines+markers',
                    name='Normal TÃ¼ketim',
                    line=dict(color='blue', width=2),
                    marker=dict(size=10)
                ))
                
                if len(anomaly_data) > 0:
                    fig.add_trace(go.Scatter(
                        x=anomaly_data['month_name'],
                        y=anomaly_data['normalized_consumption'],
                        mode='markers',
                        name='Anomali',
                        marker=dict(color='red', size=15, symbol='diamond')
                    ))
                
                mean_val = facility_data['normalized_consumption'].mean()
                fig.add_hline(y=mean_val, line_dash="dash", line_color="green", 
                             annotation_text=f"Ortalama: {mean_val:.1f}")
                
                fig.update_layout(
                    title=f"Tesisat {selected_facility} - TÃ¼ketim Trendi",
                    xaxis_title="DÃ¶nem",
                    yaxis_title="TÃ¼ketim (mÂ³)",
                    height=400,
                    hovermode='x unified'
                )
                st.plotly_chart(fig, use_container_width=True)
            
            with col2:
                detail_data = facility_data[['month_name', 'raw_consumption', 'normalized_consumption', 'is_anomaly']].copy()
                detail_data['Durum'] = detail_data['is_anomaly'].apply(lambda x: 'ğŸš¨ ANOMALI' if x else 'âœ… Normal')
                detail_data.columns = ['DÃ¶nem', 'Ham TÃ¼ketim', 'Norm. TÃ¼ketim', '_', 'Durum']
                detail_data = detail_data.drop('_', axis=1)
                detail_data['Ham TÃ¼ketim'] = detail_data['Ham TÃ¼ketim'].round(2)
                detail_data['Norm. TÃ¼ketim'] = detail_data['Norm. TÃ¼ketim'].round(2)
                
                st.dataframe(detail_data, use_container_width=True, hide_index=True)
    
    with viz_type[1]:
        st.subheader("ğŸ“Š Genel DaÄŸÄ±lÄ±m Analizi")
        
        fig = px.box(df_analysis, y='normalized_consumption', 
                    title="TÃ¼m Tesisatlar - TÃ¼ketim DaÄŸÄ±lÄ±mÄ±",
                    labels={'normalized_consumption': 'NormalleÅŸtirilmiÅŸ TÃ¼ketim (mÂ³)'})
        fig.update_layout(height=400)
        st.plotly_chart(fig, use_container_width=True)
        
        fig2 = px.histogram(df_analysis, x='normalized_consumption', nbins=50,
                           title="TÃ¼ketim DaÄŸÄ±lÄ±mÄ± HistogramÄ±",
                           labels={'normalized_consumption': 'NormalleÅŸtirilmiÅŸ TÃ¼ketim (mÂ³)'})
        fig2.update_layout(height=400)
        st.plotly_chart(fig2, use_container_width=True)
    
    with viz_type[2]:
        st.subheader("ğŸ”„ DÃ¶nem KarÅŸÄ±laÅŸtÄ±rmasÄ±")
        
        period_stats = df_analysis.groupby('month_name').agg({
            'normalized_consumption': ['mean', 'min', 'max', 'std']
        }).round(2)
        
        fig = go.Figure()
        
        months_order = sorted(df_analysis['month_name'].unique())
        
        for month in months_order:
            month_data = df_analysis[df_analysis['month_name'] == month]['normalized_consumption']
            fig.add_trace(go.Box(y=month_data, name=month))
        
        fig.update_layout(
            title="DÃ¶nemlere GÃ¶re TÃ¼ketim Kutu Grafikleri",
            yaxis_title="NormalleÅŸtirilmiÅŸ TÃ¼ketim (mÂ³)",
            height=400
        )
        st.plotly_chart(fig, use_container_width=True)
    
    # ============ RAPOR Ä°NDÄ°R ============
    st.header("ğŸ’¾ AdÄ±m 6: Rapor Ä°ndir")
    
    if st.button("ğŸ“Š Excel Raporu OluÅŸtur", key="create_report"):
        output = BytesIO()
        
        with pd.ExcelWriter(output, engine='openpyxl') as writer:
            # Anomaliler
            anomaly_export = df_analysis[df_analysis['is_anomaly']][
                ['facility_id', 'date', 'month_name', 'raw_consumption', 
                 'days_reported', 'normalized_consumption']
            ].sort_values('normalized_consumption', ascending=False)
            anomaly_export.to_excel(writer, sheet_name='Anomaliler', index=False)
            
            # TÃ¼m Veriler
            all_export = df_analysis[['facility_id', 'date', 'month_name', 'raw_consumption',
                                      'days_reported', 'normalized_consumption', 'is_anomaly']]
            all_export.to_excel(writer, sheet_name='TÃ¼m Veriler', index=False)
            
            # Ã–zet Ä°statistikler
            summary = df_analysis.groupby('facility_id').agg({
                'normalized_consumption': ['count', 'mean', 'min', 'max', 'std']
            }).round(2)
            summary.to_excel(writer, sheet_name='Ã–zet Ä°statistikler')
        
        output.seek(0)
        st.download_button(
            label="â¬‡ï¸ Raporu Ä°ndir (Excel)",
            data=output.getvalue(),
            file_name=f"anomali_raporu_{datetime.now().strftime('%Y%m%d_%H%M%S')}.xlsx",
            mime="application/vnd.openxmlformats-officedocument.spreadsheetml.sheet"
        )

else:
    st.info("ğŸ‘ˆ BaÅŸlamak iÃ§in lÃ¼tfen Excel dosyasÄ±nÄ± yÃ¼kleyin")
